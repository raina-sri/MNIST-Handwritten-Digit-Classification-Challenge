{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Convolution2D, MaxPooling2D, Flatten\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import backend as K\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loading our datasets :containing images of handwritten digits 0f 0 - 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flatten the images to pas into the neural network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 28, 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_width, img_height)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_width, img_height)\n",
    "    input_shape = (1, img_width, img_height)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_width, img_height, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_width, img_height, 1)\n",
    "    input_shape = (img_width, img_height, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalizing our datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n",
      "(60000, 10)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "sx_train = x_train / 255\n",
    "x_test = x_test / 255\n",
    "\n",
    "train_y = to_categorical(y_train)\n",
    "test_y = to_categorical(y_test)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(train_y.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Convolution2D(filters = 32, kernel_size = (5, 5), input_shape = input_shape, activation = \"relu\"))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model.add(Convolution2D(filters = 64, kernel_size = (5, 5), input_shape = input_shape, activation = \"relu\"))\n",
    "model.add(MaxPooling2D(pool_size = (3, 3)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation = \"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compiling our model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = \"adam\",\n",
    "              loss = \"categorical_crossentropy\",#classes that are greater than 2\n",
    "              metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 8, 64)          51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 86,282\n",
      "Trainable params: 86,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 75s 1ms/step - loss: 0.6056 - accuracy: 0.8957 - val_loss: 2.2707 - val_accuracy: 0.4715\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 75s 1ms/step - loss: 0.1109 - accuracy: 0.9676 - val_loss: 2.2680 - val_accuracy: 0.6076\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 76s 1ms/step - loss: 0.0826 - accuracy: 0.9753 - val_loss: 2.2719 - val_accuracy: 0.3914\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 77s 1ms/step - loss: 0.0692 - accuracy: 0.9796 - val_loss: 2.2755 - val_accuracy: 0.3929\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 77s 1ms/step - loss: 0.0623 - accuracy: 0.9814 - val_loss: 2.2772 - val_accuracy: 0.3624\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 78s 1ms/step - loss: 0.0528 - accuracy: 0.9847 - val_loss: 2.2745 - val_accuracy: 0.2766\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 78s 1ms/step - loss: 0.0553 - accuracy: 0.9839 - val_loss: 2.2812 - val_accuracy: 0.2036\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 78s 1ms/step - loss: 0.0490 - accuracy: 0.9857 - val_loss: 2.2775 - val_accuracy: 0.1812\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 80s 1ms/step - loss: 0.0425 - accuracy: 0.9870 - val_loss: 2.2741 - val_accuracy: 0.1760\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 81s 1ms/step - loss: 0.0388 - accuracy: 0.9889 - val_loss: 2.2767 - val_accuracy: 0.1167\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 82s 1ms/step - loss: 0.0394 - accuracy: 0.9886 - val_loss: 2.2770 - val_accuracy: 0.1175\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 81s 1ms/step - loss: 0.0353 - accuracy: 0.9894 - val_loss: 2.2718 - val_accuracy: 0.1135\n",
      "10000/10000 [==============================] - 4s 388us/step\n",
      "CNN Error : 88.65%\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, train_y, validation_data = (x_test, test_y),\n",
    "          epochs = 12, #the no. of iteration over the entire dataset train on\n",
    "          batch_size = 64)\n",
    "scores = model.evaluate(x_test, test_y)\n",
    "print(\"CNN Error : %.2f%%\" % (100- scores[1] * 100))\n",
    "model.save(\"model.mnist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#predict on the first 5 test images\n",
    "predictions = model.predict(x_test[:5])\n",
    "# print our model prediction\n",
    "print(np.argmax(predictions,axis=1))\n",
    "print(test_y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
